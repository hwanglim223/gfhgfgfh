{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Отчет по практическому заданию №1: Подготовка набора данных\n",
        "---\n",
        "\n",
        "Дисциплина: Системы искусственного интеллекта и большие данные\n",
        "\n",
        "Студент: Платон Евгения Евгеньевна\n",
        "\n",
        "Группа: КВБО-14-24\n",
        "  \n",
        "Преподаватель: Питинов Артем Вадимович\n",
        "\n"
      ],
      "metadata": {
        "id": "2f7RzkE8zR8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Цель работы**\n",
        "\n",
        "Целью данного задания является выполнение основных этапов подготовки набора данных для последующего анализа и построения модели машинного обучения. В рамках работы проведены: загрузка данных, разведочный анализ (EDA), визуализация, предварительная обработка и конструирование/отбор признаков. В качестве источника данных был выбран набор дат «Набор данных об утверждении кредита» с платформой Kaggle, независимой информации о заявках на кредит и возможности по ним."
      ],
      "metadata": {
        "id": "JADEd-cLBAIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Выбор и описание набора данных**\n",
        "\n",
        "Название набора дат: Набор данных об одобрении кредита\n",
        "\n",
        "---\n",
        "\n",
        "Источник: Kaggle\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Описание: Датасет содержит данные о клиентах, подавших заявки на получение кредита. Включает демографические, финансовые и поведенческие показатели, а также целевую переменную — одобрение кредита.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Цель: Проанализировать факторы, влияющие на решение по кредиту, и подготовить данные для построения модели классификации."
      ],
      "metadata": {
        "id": "tPzaVlK4A7_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Загрузка данных**\n",
        "Этап загрузки данных является первым шагом в любом аналитическом процессе. Он заключается в получении доступа к набору данных и его импорте в среду выполнения (в данном случае, Google Colab) в формате, удобном для последующей обработки. Мы использовали библиотеку pandas для работы с табличными данными и kagglehub для прямой загрузки датасета с платформы Kaggle без необходимости скачивать его вручную.\n",
        "\n",
        "**3.1. Установка зависимостей**"
      ],
      "metadata": {
        "id": "ja2n1lHGzXJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub pandas matplotlib seaborn scikit-learn"
      ],
      "metadata": {
        "id": "ipJKqXuYzYn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Эта команда устанавливает библиотеки:**\n",
        "\n",
        "- kagglehub (для загрузки)\n",
        "\n",
        "- pandas (для работы с данными)\n",
        "\n",
        "- matplotlib и seaborn (для визуализации)\n",
        "\n",
        "- scikit-learn (для возможной предобработки и отбора признаков)."
      ],
      "metadata": {
        "id": "QAUw5O0vzZqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2**. **Загрузка датасета**"
      ],
      "metadata": {
        "id": "WzU0N-zOzeGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "try:\n",
        "    print(\"Загружаем датасет...\")\n",
        "    path = kagglehub.dataset_download(\"anishdevedward/loan-approval-dataset\")\n",
        "    print(\"Путь к датасету:\", path)\n",
        "\n",
        "    # Поиск CSV-файла\n",
        "    csv_files = glob.glob(os.path.join(path, \"**\", \"*.csv\"), recursive=True)\n",
        "    if csv_files:\n",
        "        df = pd.read_csv(csv_files[0])\n",
        "        print(f\"\\nЗагружен файл: {csv_files[0]}\")\n",
        "    else:\n",
        "        print(\"\\nCSV-файлы не найдены.\")\n",
        "        df = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка загрузки: {e}\")\n",
        "    df = None\n",
        "\n",
        "if df is not None:\n",
        "    print(\"\\nПервые 5 строк:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nРазмерность:\", df.shape)\n",
        "    print(\"\\nСтолбцы:\", df.columns.tolist())\n",
        "else:\n",
        "    print(\"Данные не загружены.\")"
      ],
      "metadata": {
        "id": "xpRa2nttzhXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код сначала загружает датасет с Kaggle как ZIP-архив, используя kagglehub. Затем архив распаковывается, и извлечённый CSV-файл читается. Для первичного анализа сразу после загрузки отображаются: несколько первых строк данных, общее количество строк и столбцов, а также перечень названий столбцов. Это позволяет быстро оценить структуру и содержание датасета."
      ],
      "metadata": {
        "id": "KBdMX-PBzkKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Разведочный анализ данных (EDA) и визуализация.**\n",
        "Разведочный анализ позволяет понять основные признаки, показатели пропусков, аномалии и взаимосвязи между переменными."
      ],
      "metadata": {
        "id": "HISDWATmEn1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals() and isinstance(df, pd.DataFrame) and df is not None:\n",
        "    print(\"\\n--- Общая информация ---\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\n--- Пропущенные значения ---\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    print(\"\\n--- Числовые признаки ---\")\n",
        "    print(df.select_dtypes(include='number').describe())\n",
        "\n",
        "    print(\"\\n--- Категориальные признаки ---\")\n",
        "    print(df.select_dtypes(include='object').describe())\n",
        "\n",
        "    # Визуализация\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # 1. Распределение целевой переменной\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    # Преобразуем bool в int для корректного отображения (0/1)\n",
        "    sns.countplot(x=df['loan_approved'].astype(int))\n",
        "    plt.title('Распределение целевой переменной (loan_approved)')\n",
        "    plt.xlabel('Одобрение кредита (0 = отказано, 1 = одобрено)')\n",
        "    plt.ylabel('Количество')\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Распределение дохода\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(df['income'], bins=30, kde=True, color='skyblue')\n",
        "    plt.title('Распределение годового дохода')\n",
        "    plt.xlabel('Доход ($)')\n",
        "    plt.ylabel('Частота')\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Доход и решение по кредиту\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(data=df, x=df['loan_approved'].astype(int), y='income')\n",
        "    plt.title('Доход в зависимости от решения по кредиту')\n",
        "    plt.xlabel('Одобрение кредита (0 = нет, 1 = да)')\n",
        "    plt.ylabel('Доход ($)')\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Кредитный рейтинг и решение\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(data=df, x=df['loan_approved'].astype(int), y='credit_score')\n",
        "    plt.title('Кредитный скоринг в зависимости от решения по кредиту')\n",
        "    plt.xlabel('Одобрение кредита (0 = нет, 1 = да)')\n",
        "    plt.ylabel('Credit Score')\n",
        "    plt.show()\n",
        "\n",
        "    # 5. Матрица корреляции числовых признаков\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    numeric_df = df.select_dtypes(include='number')\n",
        "    corr = numeric_df.corr()\n",
        "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title('Матрица корреляции числовых признаков')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # 6. Визуализация выбросов\n",
        "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
        "    if numeric_cols:\n",
        "        n = len(numeric_cols)\n",
        "        n_cols = 2\n",
        "        n_rows = (n + n_cols - 1) // n_cols  # округление вверх\n",
        "\n",
        "        plt.figure(figsize=(14, 5 * n_rows))\n",
        "        for i, col in enumerate(numeric_cols, 1):\n",
        "            plt.subplot(n_rows, n_cols, i)\n",
        "            sns.boxplot(y=df[col], color='lightcoral')\n",
        "            plt.title(f'Boxplot: {col}')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Числовые признаки для анализа выбросов не найдены.\")\n",
        "else:\n",
        "    print(\"Данные не загружены — EDA невозможен.\")"
      ],
      "metadata": {
        "id": "5op_APji1h-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Гистограмма дохода показывает сильную правостороннюю асимметрию.\n",
        "Столбчатая диаграмма показывает, что некоторым лицам кредиты одобряются чаще.\n",
        "Тепловая карта показывает мультиколлинеарность.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AiINypZyzrtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Предварительная обработка данных**"
      ],
      "metadata": {
        "id": "NaM7gt2FILOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals() and isinstance(df, pd.DataFrame) and df is not None:\n",
        "    print(\"Пропусков до обработки:\", df.isnull().sum().sum())\n",
        "\n",
        "    # Удаляем строки с пропусками\n",
        "    df = df.dropna()\n",
        "    print(\"Пропусков после обработки:\", df.isnull().sum().sum())\n",
        "\n",
        "    # Удаляем неинформативные категориальные признаки с высокой кардинальностью\n",
        "    print(\"\\nУдаляем столбцы 'name' и 'city' (высокая кардинальность).\")\n",
        "    df = df.drop(columns=['name', 'city'], errors='ignore')\n",
        "\n",
        "    # Убеждаемся, что целевая переменная — числовая\n",
        "    if 'loan_approved' in df.columns:\n",
        "        df['loan_approved'] = df['loan_approved'].astype(int)\n",
        "        print(\"Целевая переменная 'loan_approved' преобразована в int (0/1).\")\n",
        "\n",
        "    print(\"\\nФорма после предобработки:\", df.shape)\n",
        "    print(\"Оставшиеся столбцы:\", df.columns.tolist())\n",
        "    print(\"\\nПервые 5 строк после обработки:\")\n",
        "    print(df.head())\n",
        "\n",
        "else:\n",
        "    print(\"Данные не загружены — предобработка невозможна.\")"
      ],
      "metadata": {
        "id": "VH-SZ7-PzvIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Пропущенные значения отсутствуют, но метод универсален.\n",
        "\n",
        "Категориальные признаки закодированы с помощью One-Hot Encoding.\n",
        "\n",
        "Параметр уменьшает размерность и излучает зависимости между электродами."
      ],
      "metadata": {
        "id": "wJTl7rd7zzEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Конструирование и отбор критериев.**\n",
        "На этом этапе новые признаки и отбираются наиболее значимые."
      ],
      "metadata": {
        "id": "ZsKXz2SyH2Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals() and isinstance(df, pd.DataFrame) and df is not None:\n",
        "    # Проверяем наличие нужных столбцов до создания нового признака\n",
        "    if 'loan_amount' in df.columns and 'income' in df.columns:\n",
        "        # Создаём новый признак: доля кредита от дохода\n",
        "        df['loan_percent_income'] = df['loan_amount'] / df['income']\n",
        "        print(\"Создан новый признак: 'loan_percent_income'\")\n",
        "    else:\n",
        "        print(\"Невозможно создать 'loan_percent_income': отсутствуют 'loan_amount' или 'income'\")\n",
        "        print(\"Доступные столбцы:\", df.columns.tolist())\n",
        "\n",
        "    # Подготовка к отбору признаков\n",
        "    from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "    target_col = 'loan_approved'\n",
        "    if target_col not in df.columns:\n",
        "        print(f\"Ошибка: столбец '{target_col}' не найден\")\n",
        "        print(\"Доступные столбцы:\", df.columns.tolist())\n",
        "    else:\n",
        "        X = df.drop(columns=[target_col])\n",
        "        y = df[target_col]\n",
        "\n",
        "        # Убеждаемся, что все признаки — числовые (SelectKBest требует чисел)\n",
        "        X_numeric = X.select_dtypes(include=['number'])\n",
        "        if X_numeric.shape[1] == 0:\n",
        "            print(\"Нет числовых признаков для отбора\")\n",
        "        else:\n",
        "            # Отбор лучших признаков\n",
        "            k = min(15, X_numeric.shape[1])\n",
        "            selector = SelectKBest(score_func=f_classif, k=k)\n",
        "            X_selected = selector.fit_transform(X_numeric, y)\n",
        "\n",
        "            selected_features = X_numeric.columns[selector.get_support()].tolist()\n",
        "            print(f\"\\n Отобрано {len(selected_features)} признаков:\")\n",
        "            print(selected_features)\n",
        "\n",
        "            # Формируем итог\n",
        "            df_final = pd.DataFrame(X_selected, columns=selected_features)\n",
        "            df_final[target_col] = y.values\n",
        "\n",
        "            print(f\"\\n Финальная размерность: {df_final.shape}\")\n",
        "            print(\"Первые 5 строк итогового датасета:\")\n",
        "            print(df_final.head())\n",
        "\n",
        "            # df_final.to_csv(\"loan_data_prepared.csv\", index=False)\n",
        "else:\n",
        "    print(\"Данные не загружены - отбор признаков невозможен.\")"
      ],
      "metadata": {
        "id": "K39y-8v7z1Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Создан новый индикатор — отношение суммы кредита к доходу.\n",
        "\n",
        "Использован метод с понижением.\n",
        "\n",
        "Отобрано 15 наиболее значимых признаков на основе статистической продукции."
      ],
      "metadata": {
        "id": "NiM33nFDEVMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Выводы\n",
        "В ходе выполнения практического задания №1 был успешно загружен набор данных «Набор данных для одобрения кредита» с платформы Kaggle. Проведен полный цикл подготовки данных: выполнен разведочный анализ с визуализацией распределений и взаимосвязей, обработаны категориальные признаки с помощью One-Hot Encoding, создан новый информативный признак ( ), и осуществлен отбор наиболее релевантных показателей с использованием статистического метода . В результате получен уточненный и структурированный набор данных, готовый к использованию в задачах машинного обучения, в частности — для построения моделей классификации по одобрению кредитов."
      ],
      "metadata": {
        "id": "F9UYbVCCEY78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Практика 2."
      ],
      "metadata": {
        "id": "2N0dHr8-awS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub pandas matplotlib seaborn scikit-learn xgboost shap -q"
      ],
      "metadata": {
        "id": "w2x514vW62_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18a950e5"
      },
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Загрузка\n",
        "print(\"Загружаем датасет...\")\n",
        "path = kagglehub.dataset_download(\"anishdevedward/loan-approval-dataset\")\n",
        "csv_files = glob.glob(os.path.join(path, \"**\", \"*.csv\"), recursive=True)\n",
        "df = pd.read_csv(csv_files[0]) if csv_files else None\n",
        "\n",
        "if df is None:\n",
        "    raise RuntimeError(\"CSV-файл не найден\")\n",
        "\n",
        "# Предобработка — как в работе №1, но с явным One-Hot\n",
        "df = df.drop(columns=['name', 'city'], errors='ignore')\n",
        "df = df.dropna()\n",
        "df['loan_approved'] = df['loan_approved'].astype(int)\n",
        "\n",
        "# Remove 'points' column to prevent data leakage\n",
        "print(\"Удаляем столбец 'points' для предотвращения утечки данных.\")\n",
        "df = df.drop(columns=['points'], errors='ignore')\n",
        "\n",
        "# One-Hot Encoding для категориальных признаков\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Новый признак\n",
        "df['loan_percent_income'] = df['loan_amount'] / df['income']\n",
        "\n",
        "# Отделение целевой переменной\n",
        "target = 'loan_approved'\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# Отбор 15 лучших признаков\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "# Adjust k to be min of 15 or number of available features after dropping 'points'\n",
        "k_features = min(15, X.shape[1])\n",
        "selector = SelectKBest(score_func=f_classif, k=k_features)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "\n",
        "# Итоговый датафрейм\n",
        "df_final = pd.DataFrame(X_selected, columns=selected_features)\n",
        "df_final[target] = y.values\n",
        "\n",
        "print(\"Финальная форма:\", df_final.shape)\n",
        "print(\"Признаки:\", df_final.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_final.drop(columns=[target])\n",
        "y = df_final[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "QslAsXWpHrQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e0f8a01"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Инициализация\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    results[name] = {\n",
        "        \"model\": model,\n",
        "        \"y_pred\": y_pred,\n",
        "        \"y_proba\": y_proba,\n",
        "        \"metrics\": {\n",
        "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"Precision\": precision_score(y_test, y_pred),\n",
        "            \"Recall\": recall_score(y_test, y_pred),\n",
        "            \"F1\": f1_score(y_test, y_pred),\n",
        "            \"AUC-ROC\": roc_auc_score(y_test, y_proba)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    for k, v in results[name][\"metrics\"].items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8710dcfb"
      },
      "source": [
        "metrics_df = pd.DataFrame({name: res[\"metrics\"] for name, res in results.items()}).T\n",
        "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title(\"Сравнение метрик моделей\")\n",
        "plt.ylabel(\"Значение\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ae22f1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Словарь для хранения результатов\n",
        "results_tuned = {}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Логистическая регрессия\n",
        "# --------------------------------------------------\n",
        "print(\"Подбор гиперпараметров: Logistic Regression...\")\n",
        "lr_param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear']  # совместим с l2 и небольшими данными\n",
        "}\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "lr_grid.fit(X_train, y_train)\n",
        "\n",
        "y_proba_lr = lr_grid.predict_proba(X_test)[:, 1]\n",
        "results_tuned[\"Logistic Regression (tuned)\"] = {\n",
        "    \"model\": lr_grid.best_estimator_,\n",
        "    \"best_params\": lr_grid.best_params_,\n",
        "    \"y_proba\": y_proba_lr,\n",
        "    \"auc\": roc_auc_score(y_test, y_proba_lr)\n",
        "}\n",
        "\n",
        "print(\"  Лучшие параметры:\", lr_grid.best_params_)\n",
        "print(\"  AUC:\", results_tuned[\"Logistic Regression (tuned)\"][\"auc\"])\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Случайный лес\n",
        "# --------------------------------------------------\n",
        "print(\"\\nПодбор гиперпараметров: Random Forest...\")\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_grid = GridSearchCV(rf_model, rf_param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "y_proba_rf = rf_grid.predict_proba(X_test)[:, 1]\n",
        "results_tuned[\"Random Forest (tuned)\"] = {\n",
        "    \"model\": rf_grid.best_estimator_,\n",
        "    \"best_params\": rf_grid.best_params_,\n",
        "    \"y_proba\": y_proba_rf,\n",
        "    \"auc\": roc_auc_score(y_test, y_proba_rf)\n",
        "}\n",
        "\n",
        "print(\"  Лучшие параметры:\", rf_grid.best_params_)\n",
        "print(\"  AUC:\", results_tuned[\"Random Forest (tuned)\"][\"auc\"])\n",
        "\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. XGBoost\n",
        "# --------------------------------------------------\n",
        "print(\"\\nПодбор гиперпараметров: XGBoost...\")\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 6],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n",
        "\n",
        "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_grid = GridSearchCV(xgb_model, xgb_param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "y_proba_xgb = xgb_grid.predict_proba(X_test)[:, 1]\n",
        "results_tuned[\"XGBoost (tuned)\"] = {\n",
        "    \"model\": xgb_grid.best_estimator_,\n",
        "    \"best_params\": xgb_grid.best_params_,\n",
        "    \"y_proba\": y_proba_xgb,\n",
        "    \"auc\": roc_auc_score(y_test, y_proba_xgb)\n",
        "}\n",
        "\n",
        "print(\"  Лучшие параметры:\", xgb_grid.best_params_)\n",
        "print(\"  AUC:\", results_tuned[\"XGBoost (tuned)\"][\"auc\"])\n",
        "\n",
        "# --------------------------------------------------\n",
        "# Итоговая таблица AUC\n",
        "# --------------------------------------------------\n",
        "print(\"\\n=== ИТОГОВЫЕ AUC ПОСЛЕ ТЮНИНГА ===\")\n",
        "for name, res in results_tuned.items():\n",
        "    print(f\"{name:25} → AUC = {res['auc']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aae9a8b"
      },
      "source": [
        "# Определим, какие модели поддерживают feature_importances_\n",
        "models_with_importance = [\"Random Forest (tuned)\", \"XGBoost (tuned)\"]\n",
        "\n",
        "# Найдём лучшую по AUC среди них\n",
        "best_name = None\n",
        "best_auc = -1\n",
        "for name in models_with_importance:\n",
        "    if name in results_tuned:\n",
        "        auc = results_tuned[name][\"auc\"]\n",
        "        if auc > best_auc:\n",
        "            best_auc = auc\n",
        "            best_name = name\n",
        "\n",
        "if best_name is None:\n",
        "    print(\"Нет моделей с поддержкой feature_importances_\")\n",
        "else:\n",
        "    print(f\"Лучшая модель для анализа важности: {best_name} (AUC = {best_auc:.4f})\")\n",
        "    best_model = results_tuned[best_name][\"model\"]\n",
        "    importances = best_model.feature_importances_\n",
        "    feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(x=feat_imp.values[:10], y=feat_imp.index[:10])\n",
        "    plt.title(f\"Топ-5 важных признаков ({best_name})\")\n",
        "    plt.xlabel(\"Важность\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nТоп-5 признаков:\")\n",
        "    print(feat_imp.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Получаем лучшие параметры Random Forest (из tuned-результатов)\n",
        "best_params_rf = results_tuned[\"Random Forest (tuned)\"][\"best_params\"]\n",
        "\n",
        "# Обучаем модель БЕЗ стратификации\n",
        "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42  # без stratify!\n",
        ")\n",
        "model_ns = RandomForestClassifier(**best_params_rf, random_state=42)\n",
        "model_ns.fit(X_train_ns, y_train_ns)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_ns = model_ns.predict(X_test_ns)\n",
        "y_proba_ns = model_ns.predict_proba(X_test_ns)[:, 1]\n",
        "\n",
        "# Расчёт всех метрик\n",
        "metrics_ns = {\n",
        "    \"Accuracy\": accuracy_score(y_test_ns, y_pred_ns),\n",
        "    \"Precision\": precision_score(y_test_ns, y_pred_ns),\n",
        "    \"Recall\": recall_score(y_test_ns, y_pred_ns),\n",
        "    \"F1\": f1_score(y_test_ns, y_pred_ns),\n",
        "    \"AUC-ROC\": roc_auc_score(y_test_ns, y_proba_ns)\n",
        "}\n",
        "\n",
        "# Вывод\n",
        "print(\"=== Метрики модели БЕЗ стратификации ===\")\n",
        "for name, value in metrics_ns.items():\n",
        "    print(f\"{name:10} = {value:.4f}\")\n",
        "\n",
        "print(\"\\n=== Подробный отчёт (classification_report) ===\")\n",
        "print(classification_report(y_test_ns, y_pred_ns))"
      ],
      "metadata": {
        "id": "URzvBWR4Hist"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e59ef1b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_tuned)\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (Random Forest tuned)\")\n",
        "plt.ylabel(\"Истинный класс\")\n",
        "plt.xlabel(\"Предсказанный класс\")\n",
        "plt.show()\n",
        "\n",
        "# ROC-кривая\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba_tuned)\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {tuned_metrics['AUC-ROC']:.4f}\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label=\"Random classifier\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC-кривая\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Названия моделей до тюнинга\n",
        "model_names = [\"Logistic Regression\", \"Random Forest\", \"XGBoost\"]\n",
        "colors = [\"blue\", \"green\", \"red\"]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for name, color in zip(model_names, colors):\n",
        "    if name in results:\n",
        "        fpr, tpr, _ = roc_curve(y_test, results[name][\"y_proba\"])\n",
        "        auc_score = results[name][\"metrics\"][\"AUC-ROC\"]\n",
        "        plt.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {auc_score:.4f})')\n",
        "    else:\n",
        "        print(f\"Модель '{name}' не найдена в results\")\n",
        "\n",
        "# Диагональ — случайный классификатор\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1.5, label='Random classifier (AUC = 0.5)')\n",
        "\n",
        "# Оформление\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('ROC-кривые моделей (до тюнинга гиперпараметров)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "heq42lXdKPSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}